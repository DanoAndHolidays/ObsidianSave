==Ke G, Meng Q, Finley T, et al. LightGBM: A highly efficient gradient boosting decision tree[ C ]// _Advances in Neural Information Processing Systems 30 (NeurIPS 2017)_. 2017.==

以下是 LightGBM 原论文（NeurIPS 2017）的**中文翻译简介与规范引用**：
## 中文翻译简介

**论文题目**：  
LightGBM：一种高效的梯度提升决策树

**作者**：  
柯国霖（Guolin Ke）、孟琦（Qi Meng）、Thomas Finley、汪泰峰（Taifeng Wang）、陈炜（Wei Chen）、马伟东（Weidong Ma）、叶启伟（Qiwei Ye）、刘铁岩（Tie-Yan Liu）  
（微软亚洲研究院、北京大学、微软雷德蒙分部）

**摘要翻译**：  
梯度提升决策树（GBDT）是当前最流行的机器学习算法之一，拥有 XGBoost、pGBRT 等多种高效实现。然而在高维特征和大规模数据下，现有实现的效率和可扩展性仍不理想。主要原因是每个特征都需要遍历全部样本来评估所有可能分裂点的信息增益，计算量大。为了解决这一难题，本文提出了两种创新技术：**基于梯度的单边采样（GOSS）** 和 **互斥特征捆绑（EFB）**。

- GOSS：优先保留梯度大的样本，仅对梯度小的样本随机采样，从而在显著减少样本量的情况下，依然可以准确估计分裂点的信息增益。
    
- EFB：将互斥（极少同时非零）的特征进行捆绑，有效减少特征数，提高计算效率。  
    理论与实验均表明，LightGBM 能在基本不损失精度的前提下，将训练速度提升 20 倍以上。
    

**论文正文内容**（部分）：
- LightGBM 是一种融合 GOSS 和 EFB 的高效 GBDT 算法，显著加速大数据场景下的模型训练；
    
- 实验在多个公开大规模数据集（如 KDD Cup、LETOR、Allstate）上进行了测试，结果显示 LightGBM 比传统 GBDT、XGBoost 等工具快很多，且精度相当；
    
- 代码开源：[https://github.com/Microsoft/LightGBM](https://github.com/Microsoft/LightGBM)
    
- 适用于高维稀疏特征、高样本量的机器学习、医学判别、风控等领域。
    

- **中文格式（GB/T 7714）**  
    柯国霖, 孟琦, Thomas Finley, 等. LightGBM: 一种高效的梯度提升决策树[C]// 神经信息处理系统大会（NeurIPS 2017）, 美国加州长滩, 2017.  
    可下载全文: [https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf](https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)
    
- **APA 7 格式**  
    Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., & Liu, T.-Y. (2017). LightGBM: A highly efficient gradient boosting decision tree. In _Advances in Neural Information Processing Systems 30 (NeurIPS 2017)_. [https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf](https://papers.nips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)
---

==Ishwaran H, Kogalur U B, Blackstone E H, 等. Random survival forests[J]. The Annals of Applied Statistics, 2008, 2(3): 841–860.==

## 中文内容简介（要点分列）

- **研究内容**：  
    本文提出了一种用于生存数据（即“删失数据”）分析的新型机器学习算法——**随机生存森林**（Random Survival Forests, RSF），它是决策树集成算法（即随机森林）的生存分析扩展。
    
- **核心思想**：
    
    - 利用随机森林思想（Bagging + 随机特征选择）对生存（时间到事件、带删失）数据建模。
        
    - 每棵树基于 Bootstrap 重采样样本构建，节点分裂依据“最大化生存差异”（如 log-rank 统计量）。
        
    - 集成大量树，最终输出累计生存概率（或风险函数），对个体的生存时间/达标概率进行非参数估计。
        
- **主要优点**：
    
    - 能处理高维、多变量、非线性、强交互的数据；
        
    - 对删失（右删失）数据天然支持，无需分布假设；
        
    - 可输出变量重要性、个体生存概率曲线等丰富信息；
        
    - 适合用于医学、生物统计、工业可靠性等领域的“时间到事件”预测。
        
- **应用场景**：
    
    - 论文应用于医学（如手术患者存活）、风险预测等多种生存数据分析，实际效果显著优于经典 Cox 比例风险模型等。
        


---
好的，以下是**第⑦、⑧篇论文**（分别关于**代价敏感学习**和**选择性预测/拒判**）的**规范引用**和简明中文内容简介：

---

## 第⑦篇：代价敏感学习（Cost-Sensitive Learning）

### 规范引用


**GB/T 7714 格式**  
==Elkan C. The foundations of cost-sensitive learning[C]// Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI), Workshop on Cost-Sensitive Learning. 2001: 973-978.==

### 中文内容简介

- **研究内容**：  
    该文是代价敏感学习（Cost-Sensitive Learning）领域的经典基础文献，系统分析了在类别不平衡或不同类型误分类带来不同代价（如漏诊/误诊）情况下的机器学习算法设计问题。
    
- **核心观点**：
    
    - 传统机器学习最小化“错误率”，但现实中不同类型错误（如漏诊和误诊）造成的后果（成本）不同。
        
    - 代价敏感学习框架：引入“代价矩阵”或“样本权重”，在训练与预测时动态调整模型，降低高代价错误（如漏诊）。
        
    - 可以通过修改损失函数、调整阈值、重采样等方法实现。
        
- **实际意义**：
    
    - 医学诊断、金融风控等高风险场景中，往往需要优先降低高代价事件（如“漏诊”）。
        
    - 可与 LightGBM、逻辑回归等方法配合，用于你题目第四问中的“漏诊/误诊权重调节”策略。
        

---

## 第⑧篇：选择性预测/拒判（Selective Prediction/Classification with Reject Option）

### 规范引用（以经典理论为代表）
**GB/T 7714 格式**  
==Chow C K. On optimum recognition error and reject tradeoff[J]. IEEE Transactions on Information Theory, 1970, 16(1): 41–46.==

### 中文内容简介

- **研究内容**：  
    这是“拒判理论”（选择性预测、带拒绝选项分类）的奠基性论文，首次提出“可拒判分类器”的理论与误差—拒判权衡公式。
    
- **核心思想**：
    
    - 对于置信度低的预测样本，模型可以选择“不做判定”而拒绝输出（如临床建议“复检”），以降低整体误差率。
        
    - 数学上，通过设置拒判阈值，在降低错误率和提升拒判率之间取得最优平衡。
        
- **实际应用**：
    
    - 在医学、金融等高风险领域，用于对“模型不确定”的样本自动触发“建议复检/人工判定”，提升整体安全性。
        
    - 你的题目第四问用到选择性/拒判机制时，可引用该理论基础，说明在低置信度样本上采用拒判能有效降低误判风险。